# ===========================
# Kafka connection
# ===========================
KAFKA_BROKERS=localhost:9092
KAFKA_CLIENT_ID=writer-kafka
KAFKA_TOPIC=clickhouse_ingest
KAFKA_CREATE_TOPIC=1           # 1=create if missing; 0=skip

# Producer behavior
INSERT_RATE=10000              # events/sec to generate
PRODUCER_LINGER_MS=5           # batching hint for Kafka producer (0..50 is typical)
PRODUCER_ACKS=all              # 0|1|all
PRODUCER_COMPRESSION=zstd      # none|gzip|snappy|lz4|zstd

# Client-side batching before send() (producer-side)
KAFKA_BATCH_SIZE=5000          # messages per send()
KAFKA_FLUSH_MS=200             # flush at least every N ms even if batch not full

# ===========================
# ClickHouse sink consumer (Kafka -> CH)
# ===========================
CH_HOST=http://localhost:8123
CH_DATABASE=default
CH_USER=default
CH_PASSWORD=12345678.
TABLE_NAME=drill_events_test

# ---- Time-based buffering (new) ----
BUFFER_SECONDS=20              # flush to CH every 20 seconds (fixed interval)
MAX_BUFFER_ROWS=1000000        # safety cap; flush early if exceeded

# (Old size/time controls no longer used; kept for reference)
# SINK_BATCH_ROWS=100000       # rows per CH insert (size-based)
# SINK_FLUSH_MS=5000           # flush every N ms (time-based)

# CH async insert toggles
ASYNC_INSERT=1
WAIT_FOR_ASYNC_INSERT=1
# Optional coalescing nudges (set only if you need them)
# ASYNC_INSERT_BUSY_TIMEOUT_MS=30000
# MIN_INSERT_BLOCK_SIZE_ROWS=100000
# MIN_INSERT_BLOCK_SIZE_BYTES=33554432

# Optional extra debug printing cadence (ms)
DEBUG_SETTINGS_INTERVAL_MS=15000
