# ===========================
# Kafka connection
# ===========================
KAFKA_BROKERS=localhost:9092
KAFKA_TOPIC=clickhouse_ingest
KAFKA_GROUP=ch_group             # consumer group ClickHouse will use for offsets

# Producer behavior
KAFKA_CLIENT_ID=writer-kafka
INSERT_RATE=10000                # events/sec to generate
PRODUCER_LINGER_MS=5             # small wait to batch client sends
PRODUCER_ACKS=all                # durability (all = safest)
PRODUCER_COMPRESSION=zstd        # compression: none|gzip|snappy|lz4|zstd
KAFKA_BATCH_SIZE=5000            # local batch in producer before send
KAFKA_FLUSH_MS=200               # flush at least this often

# ===========================
# ClickHouse connection
# ===========================
CH_HOST=http://localhost:8123
CH_DATABASE=default
CH_USER=default
CH_PASSWORD=12345678.

# ===========================
# CH Kafka engine + MV tuning
# ===========================
TARGET_TABLE=drill_events_test   # final MergeTree table
KAFKA_SRC_TABLE=kafka_src        # Kafka engine source
MV_NAME=mv_kafka_to_events       # Materialized View sink

# ---- Flush cadence from MV to MergeTree ----
# Default: flush roughly every 20s worth of rows
STREAM_FLUSH_INTERVAL_MS=20000   # ˜ 20s buffer before writing

# ---- Kafka source engine batch tuning ----
KAFKA_MAX_BLOCK_SIZE=100000      # max rows per batch block
KAFKA_POLL_MAX_BATCH_SIZE=100000 # max messages fetched per poll
KAFKA_POLL_TIMEOUT_MS=1000       # 1s poll interval for Kafka engine


SAFE_MODE=0
